{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter definition - Support threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_support=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singletons Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "569\n"
     ]
    }
   ],
   "source": [
    "singletons = {}\n",
    "\n",
    "\n",
    "with open(\"../data/ItemBasketDataset/transactions.dat\", 'r') as f:\n",
    "        dataset = csv.reader(f)\n",
    "        file = [frozenset(row[0].split()) for row in dataset]\n",
    "len_file=len(file)\n",
    "for i in file:\n",
    "            for j in i:\n",
    "                if j in singletons:\n",
    "                    singletons[j.strip()] += 1\n",
    "                else:\n",
    "                    singletons[j.strip()] = 1\n",
    "\n",
    "first2pairs = {k: singletons[k] for k in list(singletons)[:5]}\n",
    "print(len_file)\n",
    "\n",
    "for i in singletons.copy():\n",
    "    if singletons[i]<min_support:\n",
    "        singletons.pop(i)\n",
    "first2pairs = {k: singletons[k] for k in list(singletons)[:5]}\n",
    "print(len(singletons))\n",
    "\n",
    "singletons=set(singletons.keys())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_subsets_frequent(c, L, k):\n",
    "    for subset in (combinations(c, k)):\n",
    "        if not set(subset) in L:\n",
    "            #print(subset,L)\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "#         item_frequent = False\n",
    "#         for item in L:\n",
    "#             if  subset == set(item.split(\",\")):\n",
    "#                 item_frequent = True\n",
    "#                 break\n",
    "            \n",
    "\n",
    "#         if item_frequent == False:\n",
    "            \n",
    "#             return False\n",
    "\n",
    "#     return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateyfilter_candidates(L,k):\n",
    "    item_set=set()\n",
    "    if k==2:\n",
    "        for item in L:\n",
    "            item_set.add(item)\n",
    "    else:\n",
    "        for freq_set in L:\n",
    "            for item in set(freq_set):\n",
    "                item_set.add(item)\n",
    "    \n",
    "    #print(\"frequentes anteriores\",len(L))\n",
    "\n",
    "    #print(\"items individuales\",len(item_set))\n",
    "\n",
    "    candidates={}\n",
    "    i=0\n",
    "    for basket in file:\n",
    "        #if((i/len_file*10).is_integer()):\n",
    "          #      print(i/len_file*100,\"%\")\n",
    "        i+=1\n",
    "        items_basket =item_set.intersection(basket)\n",
    "        #print(items_basket)\n",
    "        for c in combinations(items_basket, k):\n",
    "            c = frozenset(c)\n",
    "            #print(type(c))\n",
    "            if c in candidates:\n",
    "                candidates[c] += 1\n",
    "            else:\n",
    "                candidates[c] = 1\n",
    "        #candidates.update(frozenset(x) for x in combinations(items_basket, k))\n",
    "    #print(\"candidatos\",len(candidates))\n",
    "    for item in candidates.copy():\n",
    "        if candidates[item] < min_support:\n",
    "            candidates.pop(item, None)\n",
    "    #print(\"posfiltro\",len(candidates))\n",
    "\n",
    "    if k==2:\n",
    "        return set(candidates)\n",
    "    candidates = set([candidate for candidate in set(candidates) if all_subsets_frequent(candidate,L,k-1)])\n",
    "    #print(\"check de subsets\",len(candidates))\n",
    "\n",
    "    return candidates\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Support threshold: \", min_support)\n",
    "\n",
    "    frequent_sets=[singletons]\n",
    "    print(\"# of frequent sets of lenght \",1,\": \",len(singletons))\n",
    "\n",
    "    k = 2\n",
    "    while True:\n",
    "        if not frequent_sets[k-2]:\n",
    "            break\n",
    "        C = generateyfilter_candidates(frequent_sets[k-2], k)\n",
    "        print(\"# of frequent sets of lenght \",k,\": \",len(C))\n",
    "        frequent_sets.append(C)\n",
    "#         print(frequent_sets)\n",
    "        k += 1\n",
    "\n",
    "\n",
    "\n",
    "        #L = {}\n",
    "        #i=0\n",
    "#         for basket in file:\n",
    "#             if((i/len_file*100).is_integer()):\n",
    "#                 print(i/len_file*100,\"%\")\n",
    "            \n",
    "#             j=0\n",
    "#             for c in C:\n",
    "#                 if c.issubset(basket):\n",
    "#                     if c in L:\n",
    "#                         L[c] += 1\n",
    "#                     else:\n",
    "#                         L[c] = 1\n",
    "                \n",
    "#             i+=1\n",
    "    \n",
    "#         for item in L.copy():\n",
    "#             if L[item] < min_support:\n",
    "#                 L.pop(item, None)\n",
    "\n",
    "        #frequent_sets.append(sorted(L.items(), key=operator.itemgetter(0)))\n",
    "\n",
    "#frequent_sets.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support threshold:  500\n",
      "# of frequent sets of lenght  1 :  569\n",
      "# of frequent sets of lenght  2 :  342\n",
      "# of frequent sets of lenght  3 :  110\n",
      "# of frequent sets of lenght  4 :  43\n",
      "# of frequent sets of lenght  5 :  9\n",
      "# of frequent sets of lenght  6 :  0\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-18-2d7b4f4e91cb>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-2d7b4f4e91cb>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    print \"No association rules\"\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "def generate_association_rules(itemset, min_conf, row_count):\n",
    "\n",
    "    if len(itemset) < 2:\n",
    "        print \"No association rules\"\n",
    "    else:\n",
    "        D = str(sys.argv[1])\n",
    "\n",
    "        print \"\\nMinimum Confidence Threshold: \", min_conf*100, \"%\\n\"\n",
    "\n",
    "        print \"Association rules:\\n\"\n",
    "\n",
    "        for k in range(1, len(itemset)):\n",
    "            for pair in itemset[k]:\n",
    "                for i in range(1, len(itemset[k][0][0].split(','))):\n",
    "                    for item in powerset(pair[0].split(','), i):\n",
    "                        item_sup = None\n",
    "                        for j in itemset[i-1]:\n",
    "                            if j[0] == \",\".join(item):\n",
    "                                item_sup = int(j[1])\n",
    "                        if item_sup is not None and pair[1]/float(item_sup) >= min_conf:\n",
    "                                print \",\".join(item), \"=>\", \",\".join(list(set(pair[0].split(',')) - set(item))), \"Support: \", float(\"{0:.2f}\".format(float(item_sup)/row_count))*100, \"%\", \"Confidence: \", float(\"{0:.2f}\".format(pair[1]/float(item_sup)*100)), \"%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateRules(L, supportData, minConf=0.7):  #supportData is a dict coming from scanD\n",
    "    bigRuleList = []\n",
    "    for i in range(1, len(L)):#only get the sets with two or more items\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if (i > 1):\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcConf(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    prunedH = [] #create new list to return\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq] #calc confidence\n",
    "        if conf >= minConf: \n",
    "            print (freqSet-conseq,'-->',conseq,'conf:',conf)\n",
    "            brl.append((freqSet-conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m + 1)): #try further merging\n",
    "        Hmp1 = aprioriGen(H, m+1)#create Hm+1 new candidates\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n",
    "        if (len(Hmp1) > 1):    #need at least two sets to merge\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
